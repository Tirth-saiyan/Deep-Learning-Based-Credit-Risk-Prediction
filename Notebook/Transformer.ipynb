{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3daf5ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Embedding, Dense, Dropout, Concatenate,\n",
    "    MultiHeadAttention, LayerNormalization, GlobalAveragePooling1D\n",
    ")\n",
    "from keras.saving import register_keras_serializable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8dee734",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"default of credit card clients.xls\", skiprows=1)\n",
    "df.rename(columns={\"default payment next month\": \"target\"}, inplace=True)\n",
    "df.drop(columns=['ID'], inplace=True, errors='ignore')\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "df.fillna(df.median(numeric_only=True), inplace=True)\n",
    "\n",
    "categorical_cols = ['SEX', 'EDUCATION', 'MARRIAGE']\n",
    "numerical_cols = [col for col in df.columns if col not in categorical_cols + ['target']]\n",
    "\n",
    "le_dict = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    le_dict[col] = le  \n",
    "\n",
    "scaler = StandardScaler()\n",
    "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "\n",
    "X_cat = df[categorical_cols].astype('int32').values \n",
    "X_num = df[numerical_cols].values                    \n",
    "y = df['target'].astype(int).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "526d3c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat_train, X_cat_test, X_num_train, X_num_test, y_train, y_test = train_test_split(\n",
    "    X_cat, X_num, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dee727c",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='best_tabtransformer_model.keras',\n",
    "    monitor='val_accuracy',     \n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,     \n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37c4119d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_keras_serializable()\n",
    "class TabTransformer(Model):\n",
    "    def __init__(self, num_categories, num_numerical, emb_dim=8, num_heads=2, num_layers=2, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.embedding_layers = [\n",
    "            Embedding(input_dim=n, output_dim=emb_dim) for n in num_categories\n",
    "        ]\n",
    "\n",
    "        self.attention_blocks = [\n",
    "            [\n",
    "                MultiHeadAttention(num_heads=num_heads, key_dim=emb_dim),\n",
    "                LayerNormalization(),\n",
    "                Dropout(dropout)\n",
    "            ] for _ in range(num_layers)\n",
    "        ]\n",
    "\n",
    "        self.global_pool = GlobalAveragePooling1D()\n",
    "        self.concat_dense = Dense(128, activation='relu')\n",
    "        self.out_dense = Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        cat_inputs, num_inputs = inputs\n",
    "        x_cat = [emb(cat_inputs[:, i]) for i, emb in enumerate(self.embedding_layers)]\n",
    "        x_cat = tf.stack(x_cat, axis=1)\n",
    "        for mha, norm, drop in self.attention_blocks:\n",
    "            attn_out = mha(x_cat, x_cat)\n",
    "            x_cat = norm(x_cat + drop(attn_out))\n",
    "        x_cat = self.global_pool(x_cat)\n",
    "        x = Concatenate()([x_cat, num_inputs])\n",
    "        x = self.concat_dense(x)\n",
    "        return self.out_dense(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d83e305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m286/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m\u001b[37m笏―u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7825 - loss: 0.4943\n",
      "Epoch 1: val_accuracy improved from -inf to 0.80875, saving model to best_tabtransformer_model.keras\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7835 - loss: 0.4928 - val_accuracy: 0.8087 - val_loss: 0.4585\n",
      "Epoch 2/30\n",
      "\u001b[1m286/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m\u001b[37m笏―u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8139 - loss: 0.4416\n",
      "Epoch 2: val_accuracy improved from 0.80875 to 0.81042, saving model to best_tabtransformer_model.keras\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8141 - loss: 0.4415 - val_accuracy: 0.8104 - val_loss: 0.4558\n",
      "Epoch 3/30\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8199 - loss: 0.4360\n",
      "Epoch 3: val_accuracy improved from 0.81042 to 0.81271, saving model to best_tabtransformer_model.keras\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8199 - loss: 0.4360 - val_accuracy: 0.8127 - val_loss: 0.4535\n",
      "Epoch 4/30\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8163 - loss: 0.4363\n",
      "Epoch 4: val_accuracy improved from 0.81271 to 0.81396, saving model to best_tabtransformer_model.keras\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8163 - loss: 0.4363 - val_accuracy: 0.8140 - val_loss: 0.4491\n",
      "Epoch 5/30\n",
      "\u001b[1m295/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m\u001b[37m笏―u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8226 - loss: 0.4273\n",
      "Epoch 5: val_accuracy did not improve from 0.81396\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8226 - loss: 0.4273 - val_accuracy: 0.8135 - val_loss: 0.4480\n",
      "Epoch 6/30\n",
      "\u001b[1m299/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m\u001b[37m笏―u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8205 - loss: 0.4296\n",
      "Epoch 6: val_accuracy did not improve from 0.81396\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8205 - loss: 0.4296 - val_accuracy: 0.8115 - val_loss: 0.4520\n",
      "Epoch 7/30\n",
      "\u001b[1m289/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m\u001b[37m笏―u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8215 - loss: 0.4296\n",
      "Epoch 7: val_accuracy improved from 0.81396 to 0.81458, saving model to best_tabtransformer_model.keras\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8215 - loss: 0.4295 - val_accuracy: 0.8146 - val_loss: 0.4439\n",
      "Epoch 8/30\n",
      "\u001b[1m291/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m\u001b[37m笏―u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8215 - loss: 0.4340\n",
      "Epoch 8: val_accuracy did not improve from 0.81458\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8217 - loss: 0.4337 - val_accuracy: 0.8142 - val_loss: 0.4441\n",
      "Epoch 9/30\n",
      "\u001b[1m289/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m\u001b[37m笏―u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8259 - loss: 0.4218\n",
      "Epoch 9: val_accuracy did not improve from 0.81458\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8259 - loss: 0.4219 - val_accuracy: 0.8146 - val_loss: 0.4473\n",
      "Epoch 10/30\n",
      "\u001b[1m289/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m\u001b[37m笏―u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8239 - loss: 0.4221\n",
      "Epoch 10: val_accuracy did not improve from 0.81458\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8239 - loss: 0.4222 - val_accuracy: 0.8135 - val_loss: 0.4448\n",
      "Epoch 11/30\n",
      "\u001b[1m287/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m\u001b[37m笏―u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8285 - loss: 0.4170\n",
      "Epoch 11: val_accuracy did not improve from 0.81458\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8283 - loss: 0.4173 - val_accuracy: 0.8096 - val_loss: 0.4503\n",
      "Epoch 12/30\n",
      "\u001b[1m293/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m\u001b[37m笏―u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8199 - loss: 0.4291\n",
      "Epoch 12: val_accuracy improved from 0.81458 to 0.81563, saving model to best_tabtransformer_model.keras\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8200 - loss: 0.4289 - val_accuracy: 0.8156 - val_loss: 0.4414\n",
      "Epoch 13/30\n",
      "\u001b[1m297/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m\u001b[37m笏―u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8251 - loss: 0.4190\n",
      "Epoch 13: val_accuracy did not improve from 0.81563\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8251 - loss: 0.4190 - val_accuracy: 0.8125 - val_loss: 0.4477\n",
      "Epoch 14/30\n",
      "\u001b[1m292/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m\u001b[37m笏―u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8221 - loss: 0.4253\n",
      "Epoch 14: val_accuracy improved from 0.81563 to 0.81604, saving model to best_tabtransformer_model.keras\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8221 - loss: 0.4251 - val_accuracy: 0.8160 - val_loss: 0.4459\n",
      "Epoch 15/30\n",
      "\u001b[1m290/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m\u001b[37m笏―u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8172 - loss: 0.4280\n",
      "Epoch 15: val_accuracy did not improve from 0.81604\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8174 - loss: 0.4277 - val_accuracy: 0.8152 - val_loss: 0.4520\n",
      "Epoch 16/30\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8286 - loss: 0.4132\n",
      "Epoch 16: val_accuracy did not improve from 0.81604\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8285 - loss: 0.4132 - val_accuracy: 0.8106 - val_loss: 0.4512\n",
      "Epoch 17/30\n",
      "\u001b[1m283/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m笏≫煤\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8240 - loss: 0.4234\n",
      "Epoch 17: val_accuracy improved from 0.81604 to 0.81667, saving model to best_tabtransformer_model.keras\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8241 - loss: 0.4232 - val_accuracy: 0.8167 - val_loss: 0.4408\n",
      "Epoch 18/30\n",
      "\u001b[1m292/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m\u001b[37m笏―u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8235 - loss: 0.4198\n",
      "Epoch 18: val_accuracy improved from 0.81667 to 0.81687, saving model to best_tabtransformer_model.keras\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8236 - loss: 0.4198 - val_accuracy: 0.8169 - val_loss: 0.4418\n",
      "Epoch 19/30\n",
      "\u001b[1m290/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m\u001b[37m笏―u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8283 - loss: 0.4145\n",
      "Epoch 19: val_accuracy did not improve from 0.81687\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8283 - loss: 0.4146 - val_accuracy: 0.8092 - val_loss: 0.4492\n",
      "Epoch 20/30\n",
      "\u001b[1m288/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m\u001b[37m笏―u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8281 - loss: 0.4157\n",
      "Epoch 20: val_accuracy did not improve from 0.81687\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8280 - loss: 0.4158 - val_accuracy: 0.8150 - val_loss: 0.4423\n",
      "Epoch 21/30\n",
      "\u001b[1m289/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m\u001b[37m笏―u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8256 - loss: 0.4141\n",
      "Epoch 21: val_accuracy did not improve from 0.81687\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8256 - loss: 0.4142 - val_accuracy: 0.8158 - val_loss: 0.4412\n",
      "Epoch 22/30\n",
      "\u001b[1m298/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m\u001b[37m笏―u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8190 - loss: 0.4277\n",
      "Epoch 22: val_accuracy did not improve from 0.81687\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8191 - loss: 0.4276 - val_accuracy: 0.8154 - val_loss: 0.4447\n",
      "Epoch 23/30\n",
      "\u001b[1m292/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m\u001b[37m笏―u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8216 - loss: 0.4208\n",
      "Epoch 23: val_accuracy improved from 0.81687 to 0.81771, saving model to best_tabtransformer_model.keras\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8217 - loss: 0.4207 - val_accuracy: 0.8177 - val_loss: 0.4414\n",
      "Epoch 24/30\n",
      "\u001b[1m292/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m\u001b[37m笏―u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8264 - loss: 0.4128\n",
      "Epoch 24: val_accuracy did not improve from 0.81771\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8264 - loss: 0.4128 - val_accuracy: 0.8142 - val_loss: 0.4452\n",
      "Epoch 25/30\n",
      "\u001b[1m298/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m\u001b[37m笏―u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8197 - loss: 0.4229\n",
      "Epoch 25: val_accuracy did not improve from 0.81771\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8197 - loss: 0.4228 - val_accuracy: 0.8152 - val_loss: 0.4456\n",
      "Epoch 26/30\n",
      "\u001b[1m297/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m\u001b[37m笏―u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8243 - loss: 0.4187\n",
      "Epoch 26: val_accuracy did not improve from 0.81771\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8244 - loss: 0.4186 - val_accuracy: 0.8123 - val_loss: 0.4544\n",
      "Epoch 27/30\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8255 - loss: 0.4148\n",
      "Epoch 27: val_accuracy did not improve from 0.81771\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8255 - loss: 0.4148 - val_accuracy: 0.8119 - val_loss: 0.4486\n",
      "Epoch 28/30\n",
      "\u001b[1m291/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m\u001b[37m笏―u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8263 - loss: 0.4119\n",
      "Epoch 28: val_accuracy did not improve from 0.81771\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8262 - loss: 0.4119 - val_accuracy: 0.8133 - val_loss: 0.4436\n",
      "Epoch 29/30\n",
      "\u001b[1m295/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m\u001b[37m笏―u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8295 - loss: 0.4100\n",
      "Epoch 29: val_accuracy did not improve from 0.81771\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8295 - loss: 0.4100 - val_accuracy: 0.8167 - val_loss: 0.4459\n",
      "Epoch 30/30\n",
      "\u001b[1m289/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m\u001b[37m笏―u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8292 - loss: 0.4095\n",
      "Epoch 30: val_accuracy did not improve from 0.81771\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8291 - loss: 0.4095 - val_accuracy: 0.8135 - val_loss: 0.4449\n"
     ]
    }
   ],
   "source": [
    "num_categories = [len(np.unique(X_cat[:, i])) for i in range(X_cat.shape[1])]\n",
    "model = TabTransformer(num_categories=num_categories, num_numerical=X_num.shape[1])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    [X_cat_train, X_num_train], y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    callbacks=[checkpoint],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc3a3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m188/188\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "笨 Accuracy: 0.814\n",
      "沒 F1 Score: 0.4571984435797665\n",
      "沛 ROC AUC: 0.7692434097271262\n",
      "\n",
      "沒 Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89      4673\n",
      "           1       0.64      0.35      0.46      1327\n",
      "\n",
      "    accuracy                           0.81      6000\n",
      "   macro avg       0.74      0.65      0.67      6000\n",
      "weighted avg       0.79      0.81      0.79      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = model.predict([X_cat_test, X_num_test]).ravel()\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report\n",
    "\n",
    "print(\"笨 Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"沒 F1 Score:\", f1_score(y_test, y_pred))\n",
    "print(\"沛 ROC AUC:\", roc_auc_score(y_test, y_pred_prob))\n",
    "print(\"\\n沒 Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
